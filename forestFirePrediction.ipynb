{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cb32a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-22T15:13:41.602149Z",
     "iopub.status.busy": "2025-02-22T15:13:41.601890Z",
     "iopub.status.idle": "2025-02-22T15:13:47.723437Z",
     "shell.execute_reply": "2025-02-22T15:13:47.722542Z"
    },
    "papermill": {
     "duration": 6.127503,
     "end_time": "2025-02-22T15:13:47.725124",
     "exception": false,
     "start_time": "2025-02-22T15:13:41.597621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8884f624",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-22T15:13:47.733129Z",
     "iopub.status.busy": "2025-02-22T15:13:47.732572Z",
     "iopub.status.idle": "2025-02-22T15:13:47.736173Z",
     "shell.execute_reply": "2025-02-22T15:13:47.735483Z"
    },
    "papermill": {
     "duration": 0.008816,
     "end_time": "2025-02-22T15:13:47.737421",
     "exception": false,
     "start_time": "2025-02-22T15:13:47.728605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9aede45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-22T15:13:47.743805Z",
     "iopub.status.busy": "2025-02-22T15:13:47.743602Z",
     "iopub.status.idle": "2025-02-22T15:13:47.786929Z",
     "shell.execute_reply": "2025-02-22T15:13:47.786271Z"
    },
    "papermill": {
     "duration": 0.047808,
     "end_time": "2025-02-22T15:13:47.788149",
     "exception": false,
     "start_time": "2025-02-22T15:13:47.740341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "wildfire_path = \"/kaggle/input/forest-fire-prediction-epoch-hackathon/wildfire_sizes_before_2010.csv\"\n",
    "weather_path  = \"/kaggle/input/marioo/merged_data.csv\"\n",
    "state_path    = \"/kaggle/input/forest-fire-prediction-epoch-hackathon/merged_state_data.csv\"\n",
    "\n",
    "wildfire_df = pd.read_csv(wildfire_path)\n",
    "weather_df  = pd.read_csv(weather_path)\n",
    "state_df    = pd.read_csv(state_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cb70bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-22T15:13:47.794767Z",
     "iopub.status.busy": "2025-02-22T15:13:47.794542Z",
     "iopub.status.idle": "2025-02-22T15:13:47.815400Z",
     "shell.execute_reply": "2025-02-22T15:13:47.814493Z"
    },
    "papermill": {
     "duration": 0.0258,
     "end_time": "2025-02-22T15:13:47.816910",
     "exception": false,
     "start_time": "2025-02-22T15:13:47.791110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rename columns for consistency\n",
    "weather_df.rename(columns={'year_month': 'month', 'State': 'STATE'}, inplace=True)\n",
    "state_df.rename(columns={'State': 'STATE'}, inplace=True)\n",
    "\n",
    "# Clean percentage columns (strip '%' if present and convert to float)\n",
    "state_df['Percentage of Federal Land'] = state_df['Percentage of Federal Land'].apply(lambda x: float(str(x).rstrip('%')))\n",
    "state_df['Urbanization Rate (%)'] = state_df['Urbanization Rate (%)'].apply(lambda x: float(str(x).rstrip('%')))\n",
    "\n",
    "# Convert month columns to datetime\n",
    "wildfire_df['month'] = pd.to_datetime(wildfire_df['month'], format='%Y-%m')\n",
    "weather_df['month']  = pd.to_datetime(weather_df['month'], format='%Y-%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44cf4c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-22T15:13:47.824460Z",
     "iopub.status.busy": "2025-02-22T15:13:47.824226Z",
     "iopub.status.idle": "2025-02-22T15:13:47.862654Z",
     "shell.execute_reply": "2025-02-22T15:13:47.862064Z"
    },
    "papermill": {
     "duration": 0.043579,
     "end_time": "2025-02-22T15:13:47.863927",
     "exception": false,
     "start_time": "2025-02-22T15:13:47.820348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge wildfire sizes with weather and state data\n",
    "train_df = pd.merge(wildfire_df, weather_df, on=['STATE', 'month'], how='left')\n",
    "train_df = pd.merge(train_df, state_df, on='STATE', how='left')\n",
    "\n",
    "# Complete the time series: every state for every month 1992-01 to 2010-12\n",
    "all_states = state_df['STATE'].unique()\n",
    "train_months = pd.date_range(start='1992-01-01', end='2010-12-01', freq='MS')  # MS = Month Start\n",
    "full_index = pd.MultiIndex.from_product([all_states, train_months], names=['STATE', 'month'])\n",
    "full_train_df = pd.DataFrame(index=full_index).reset_index()\n",
    "\n",
    "# Merge with existing training data (missing rows will have NaN)\n",
    "train_df = pd.merge(full_train_df, train_df, on=['STATE', 'month'], how='left')\n",
    "\n",
    "# For missing wildfire data, assume 0 fire size\n",
    "train_df['total_fire_size'] = train_df['total_fire_size'].fillna(0)\n",
    "\n",
    "# Fill missing weather features (if any) with median\n",
    "for feat in ['PRCP','EVAP','TMIN','TMAX']:\n",
    "    if feat in train_df.columns:\n",
    "        train_df[feat] = train_df[feat].fillna(train_df[feat].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5a5ff6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-22T15:13:47.870587Z",
     "iopub.status.busy": "2025-02-22T15:13:47.870386Z",
     "iopub.status.idle": "2025-02-22T15:13:47.958376Z",
     "shell.execute_reply": "2025-02-22T15:13:47.957757Z"
    },
    "papermill": {
     "duration": 0.092572,
     "end_time": "2025-02-22T15:13:47.959665",
     "exception": false,
     "start_time": "2025-02-22T15:13:47.867093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Date features\n",
    "train_df['year'] = train_df['month'].dt.year\n",
    "train_df['month_num'] = train_df['month'].dt.month\n",
    "train_df['month_sin'] = np.sin(2 * np.pi * train_df['month_num'] / 12)\n",
    "train_df['month_cos'] = np.cos(2 * np.pi * train_df['month_num'] / 12)\n",
    "train_df['year_since_1992'] = train_df['year'] - 1992\n",
    "\n",
    "# Advanced weather lag features for selected columns\n",
    "weather_cols = ['PRCP', 'TMAX']\n",
    "for col in weather_cols:\n",
    "    train_df.sort_values(['STATE', 'month'], inplace=True)\n",
    "    train_df[f'{col}_lag1'] = train_df.groupby('STATE')[col].shift(1)\n",
    "    train_df[f'{col}_lag2'] = train_df.groupby('STATE')[col].shift(2)\n",
    "    train_df[f'{col}_lag3'] = train_df.groupby('STATE')[col].shift(3)\n",
    "    train_df[f'{col}_roll3'] = train_df.groupby('STATE')[col].rolling(window=3, min_periods=1).mean().reset_index(0, drop=True)\n",
    "    train_df[f'{col}_roll6'] = train_df.groupby('STATE')[col].rolling(window=6, min_periods=1).mean().reset_index(0, drop=True)\n",
    "\n",
    "# Interaction feature: temperature spread and its rolling average\n",
    "train_df['temp_spread'] = train_df['TMAX'] - train_df['TMIN']\n",
    "train_df['temp_spread_roll3'] = train_df.groupby('STATE')['temp_spread'].rolling(window=3, min_periods=1).mean().reset_index(0, drop=True)\n",
    "\n",
    "# Compute historical (median) fire size per state and month from training data\n",
    "hist_fire = train_df.groupby(['STATE', 'month_num'])['total_fire_size'].median().reset_index()\n",
    "hist_fire.rename(columns={'total_fire_size': 'hist_fire_size'}, inplace=True)\n",
    "hist_fire['log_hist_fire_size'] = np.log1p(hist_fire['hist_fire_size'])\n",
    "train_df = pd.merge(train_df, hist_fire[['STATE', 'month_num', 'log_hist_fire_size']], on=['STATE','month_num'], how='left')\n",
    "\n",
    "# Compute historical weather medians per state and month (from training period)\n",
    "weather_hist = train_df.groupby(['STATE', 'month_num'])[['PRCP','TMAX','TMIN']].median().reset_index()\n",
    "weather_hist.rename(columns={'PRCP':'hist_PRCP','TMAX':'hist_TMAX','TMIN':'hist_TMIN'}, inplace=True)\n",
    "train_df = pd.merge(train_df, weather_hist, on=['STATE','month_num'], how='left')\n",
    "\n",
    "# Create weather anomaly features\n",
    "train_df['prcp_anomaly'] = train_df['PRCP'] - train_df['hist_PRCP']\n",
    "train_df['tmax_anomaly'] = train_df['TMAX'] - train_df['hist_TMAX']\n",
    "train_df['tmin_anomaly'] = train_df['TMIN'] - train_df['hist_TMIN']\n",
    "\n",
    "# Log-transform target variable\n",
    "train_df['log_fire_size'] = np.log1p(train_df['total_fire_size'])\n",
    "\n",
    "# One-hot encode STATE (for state-specific effects)\n",
    "state_dummies = pd.get_dummies(train_df['STATE'], prefix='STATE')\n",
    "train_df = pd.concat([train_df, state_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f858c7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-22T15:13:47.966039Z",
     "iopub.status.busy": "2025-02-22T15:13:47.965802Z",
     "iopub.status.idle": "2025-02-22T15:13:48.008061Z",
     "shell.execute_reply": "2025-02-22T15:13:48.007406Z"
    },
    "papermill": {
     "duration": 0.046859,
     "end_time": "2025-02-22T15:13:48.009439",
     "exception": false,
     "start_time": "2025-02-22T15:13:47.962580",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_cols = [\n",
    "    'year', \n",
    "    'month_num', \n",
    "    'month_sin', \n",
    "    'month_cos', \n",
    "    'year_since_1992',\n",
    "    'PRCP', \n",
    "    'PRCP_lag1', 'PRCP_lag2', 'PRCP_lag3', 'PRCP_roll3', 'PRCP_roll6',\n",
    "    'EVAP', \n",
    "    'TMIN', \n",
    "    'TMAX', \n",
    "    'TMAX_lag1', 'TMAX_lag2', 'TMAX_lag3', 'TMAX_roll3', 'TMAX_roll6',\n",
    "    'temp_spread', 'temp_spread_roll3',\n",
    "    'prcp_anomaly', 'tmax_anomaly', 'tmin_anomaly',\n",
    "    'mean_elevation', \n",
    "    'Land Area (sq mi)', \n",
    "    'Water Area (sq mi)', \n",
    "    'Total Area (sq mi)', \n",
    "    'Percentage of Federal Land', \n",
    "    'Urbanization Rate (%)',\n",
    "    'log_hist_fire_size',\n",
    "    'hist_PRCP', 'hist_TMAX', 'hist_TMIN',\n",
    "    'Value'\n",
    "]\n",
    "state_dummy_cols = [col for col in train_df.columns if col.startswith(\"STATE_\")]\n",
    "feature_cols.extend(state_dummy_cols)\n",
    "\n",
    "# Fill missing feature values with median\n",
    "train_df[feature_cols] = train_df[feature_cols].fillna(train_df[feature_cols].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54837aec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-22T15:13:48.016496Z",
     "iopub.status.busy": "2025-02-22T15:13:48.016271Z",
     "iopub.status.idle": "2025-02-22T15:13:48.037738Z",
     "shell.execute_reply": "2025-02-22T15:13:48.036921Z"
    },
    "papermill": {
     "duration": 0.02663,
     "end_time": "2025-02-22T15:13:48.039306",
     "exception": false,
     "start_time": "2025-02-22T15:13:48.012676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use data before 2010 for training and data in 2010 for validation.\n",
    "train_data = train_df[train_df['year'] < 2010].copy()\n",
    "val_data   = train_df[train_df['year'] == 2010].copy()\n",
    "\n",
    "X_train = train_data[feature_cols]\n",
    "y_train = train_data['log_fire_size']\n",
    "X_val   = val_data[feature_cols]\n",
    "y_val   = val_data['log_fire_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91eb876a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-22T15:13:48.045953Z",
     "iopub.status.busy": "2025-02-22T15:13:48.045712Z",
     "iopub.status.idle": "2025-02-22T15:16:03.342278Z",
     "shell.execute_reply": "2025-02-22T15:16:03.341575Z"
    },
    "papermill": {
     "duration": 135.301484,
     "end_time": "2025-02-22T15:16:03.343764",
     "exception": false,
     "start_time": "2025-02-22T15:13:48.042280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    param = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.05, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 50),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 50),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.7, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.7, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 3, 10),\n",
    "        'verbose': -1,\n",
    "        'seed': 41\n",
    "    }\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    cv_scores = []\n",
    "    for train_idx, valid_idx in tscv.split(X_train):\n",
    "        X_tr, X_val_cv = X_train.iloc[train_idx], X_train.iloc[valid_idx]\n",
    "        y_tr, y_val_cv = y_train.iloc[train_idx], y_train.iloc[valid_idx]\n",
    "        lgb_train_cv = lgb.Dataset(X_tr, label=y_tr)\n",
    "        lgb_val_cv = lgb.Dataset(X_val_cv, label=y_val_cv)\n",
    "        model_cv = lgb.train(param, lgb_train_cv, num_boost_round=2000,\n",
    "                             valid_sets=[lgb_val_cv],\n",
    "                             callbacks=[lgb.early_stopping(100), lgb.log_evaluation(0)])\n",
    "        preds = model_cv.predict(X_val_cv, num_iteration=model_cv.best_iteration)\n",
    "        rmse = np.sqrt(np.mean((np.expm1(preds) - np.expm1(y_val_cv)) ** 2))\n",
    "        cv_scores.append(rmse)\n",
    "    return np.mean(cv_scores)\n",
    "\n",
    "print(\"Starting hyperparameter tuning for LightGBM...\")\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "best_params = study.best_trial.params\n",
    "print(\"Best parameters found:\", best_params)\n",
    "\n",
    "# Update LightGBM parameters with tuned values\n",
    "lgb_params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'learning_rate': best_params['learning_rate'],\n",
    "    'num_leaves': best_params['num_leaves'],\n",
    "    'min_data_in_leaf': best_params['min_data_in_leaf'],\n",
    "    'feature_fraction': best_params['feature_fraction'],\n",
    "    'bagging_fraction': best_params['bagging_fraction'],\n",
    "    'bagging_freq': best_params['bagging_freq'],\n",
    "    'verbose': -1,\n",
    "    'seed': 41\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307ff28c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-22T15:16:03.371109Z",
     "iopub.status.busy": "2025-02-22T15:16:03.370850Z",
     "iopub.status.idle": "2025-02-22T15:16:09.481102Z",
     "shell.execute_reply": "2025-02-22T15:16:09.480308Z"
    },
    "papermill": {
     "duration": 6.124075,
     "end_time": "2025-02-22T15:16:09.482441",
     "exception": false,
     "start_time": "2025-02-22T15:16:03.358366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- LightGBM ---\n",
    "lgb_train_data = lgb.Dataset(X_train, label=y_train)\n",
    "lgb_val_data   = lgb.Dataset(X_val, label=y_val, reference=lgb_train_data)\n",
    "print(\"Training final LightGBM model...\")\n",
    "lgb_model = lgb.train(\n",
    "    lgb_params,\n",
    "    lgb_train_data,\n",
    "    num_boost_round=2500,\n",
    "    valid_sets=[lgb_train_data, lgb_val_data],\n",
    "    valid_names=['train', 'val'],\n",
    "    callbacks=[lgb.early_stopping(100), lgb.log_evaluation(100)]\n",
    ")\n",
    "\n",
    "# --- XGBoost ---\n",
    "xgb_params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'seed': 41\n",
    "}\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dval   = xgb.DMatrix(X_val, label=y_val)\n",
    "print(\"Training final XGBoost model...\")\n",
    "xgb_model = xgb.train(\n",
    "    xgb_params,\n",
    "    dtrain,\n",
    "    num_boost_round=2500,\n",
    "    evals=[(dtrain, 'train'), (dval, 'val')],\n",
    "    early_stopping_rounds=100,\n",
    "    verbose_eval=100\n",
    ")\n",
    "\n",
    "# --- CatBoost ---\n",
    "cat_model = CatBoostRegressor(\n",
    "    iterations=2500,\n",
    "    learning_rate=0.01,\n",
    "    depth=6,\n",
    "    loss_function='RMSE',\n",
    "    random_seed=41,\n",
    "    early_stopping_rounds=100,\n",
    "    verbose=100\n",
    ")\n",
    "print(\"Training final CatBoost model...\")\n",
    "cat_model.fit(X_train, y_train, eval_set=(X_val, y_val), use_best_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c707130c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-22T15:16:09.509264Z",
     "iopub.status.busy": "2025-02-22T15:16:09.508977Z",
     "iopub.status.idle": "2025-02-22T15:16:09.528830Z",
     "shell.execute_reply": "2025-02-22T15:16:09.527529Z"
    },
    "papermill": {
     "duration": 0.035076,
     "end_time": "2025-02-22T15:16:09.530531",
     "exception": false,
     "start_time": "2025-02-22T15:16:09.495455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lgb_pred_log = lgb_model.predict(X_val, num_iteration=lgb_model.best_iteration)\n",
    "xgb_pred_log = xgb_model.predict(dval, iteration_range=(0, xgb_model.best_iteration))\n",
    "cat_pred_log = cat_model.predict(X_val)\n",
    "\n",
    "# Ensemble (average predictions in log-space)\n",
    "ensemble_pred_log = (lgb_pred_log + xgb_pred_log + cat_pred_log) / 3.0\n",
    "\n",
    "val_pred = np.expm1(ensemble_pred_log)\n",
    "val_true = np.expm1(y_val)\n",
    "log_errors = np.abs(np.log((val_pred + 1e-9) / (val_true + 1e-9)))\n",
    "log_errors_clipped = np.minimum(log_errors, 10)\n",
    "val_score = log_errors_clipped.mean()\n",
    "print(\"Validation Ensemble Log-Error Score:\", val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582b5132",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-22T15:16:09.559952Z",
     "iopub.status.busy": "2025-02-22T15:16:09.559731Z",
     "iopub.status.idle": "2025-02-22T15:16:09.645280Z",
     "shell.execute_reply": "2025-02-22T15:16:09.644636Z"
    },
    "papermill": {
     "duration": 0.100521,
     "end_time": "2025-02-22T15:16:09.646402",
     "exception": false,
     "start_time": "2025-02-22T15:16:09.545881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Complete time series for test: every state for every month from 2011-01 to 2015-12.\n",
    "test_months = pd.date_range(start='2011-01-01', end='2015-12-01', freq='MS')\n",
    "full_test_index = pd.MultiIndex.from_product([all_states, test_months], names=['STATE', 'month'])\n",
    "full_test_df = pd.DataFrame(index=full_test_index).reset_index()\n",
    "\n",
    "# Merge with weather and state data\n",
    "test_df = pd.merge(full_test_df, weather_df, on=['STATE', 'month'], how='left')\n",
    "test_df = pd.merge(test_df, state_df, on='STATE', how='left')\n",
    "\n",
    "# Create date features for test set\n",
    "test_df['year'] = test_df['month'].dt.year\n",
    "test_df['month_num'] = test_df['month'].dt.month\n",
    "test_df['month_sin'] = np.sin(2 * np.pi * test_df['month_num'] / 12)\n",
    "test_df['month_cos'] = np.cos(2 * np.pi * test_df['month_num'] / 12)\n",
    "test_df['year_since_1992'] = test_df['year'] - 1992\n",
    "\n",
    "for col in weather_cols:\n",
    "    test_df.sort_values(['STATE', 'month'], inplace=True)\n",
    "    test_df[f'{col}_lag1'] = test_df.groupby('STATE')[col].shift(1)\n",
    "    test_df[f'{col}_lag2'] = test_df.groupby('STATE')[col].shift(2)\n",
    "    test_df[f'{col}_lag3'] = test_df.groupby('STATE')[col].shift(3)\n",
    "    test_df[f'{col}_roll3'] = test_df.groupby('STATE')[col].rolling(window=3, min_periods=1).mean().reset_index(0, drop=True)\n",
    "    test_df[f'{col}_roll6'] = test_df.groupby('STATE')[col].rolling(window=6, min_periods=1).mean().reset_index(0, drop=True)\n",
    "\n",
    "# Interaction features for test data\n",
    "test_df['temp_spread'] = test_df['TMAX'] - test_df['TMIN']\n",
    "test_df['temp_spread_roll3'] = test_df.groupby('STATE')['temp_spread'].rolling(window=3, min_periods=1).mean().reset_index(0, drop=True)\n",
    "\n",
    "# Merge historical features from training data into test set\n",
    "test_df = pd.merge(test_df, hist_fire[['STATE','month_num','log_hist_fire_size']], on=['STATE','month_num'], how='left')\n",
    "test_df = pd.merge(test_df, weather_hist, on=['STATE','month_num'], how='left')\n",
    "\n",
    "# Create weather anomaly features\n",
    "test_df['prcp_anomaly'] = test_df['PRCP'] - test_df['hist_PRCP']\n",
    "test_df['tmax_anomaly'] = test_df['TMAX'] - test_df['hist_TMAX']\n",
    "test_df['tmin_anomaly'] = test_df['TMIN'] - test_df['hist_TMIN']\n",
    "\n",
    "# One-hot encode STATE for test data\n",
    "state_dummies_test = pd.get_dummies(test_df['STATE'], prefix='STATE')\n",
    "test_df = pd.concat([test_df, state_dummies_test], axis=1)\n",
    "\n",
    "for col in feature_cols:\n",
    "    if col not in test_df.columns:\n",
    "        test_df[col] = 0\n",
    "test_df[feature_cols] = test_df[feature_cols].fillna(test_df[feature_cols].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeee7ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-22T15:16:09.672764Z",
     "iopub.status.busy": "2025-02-22T15:16:09.672561Z",
     "iopub.status.idle": "2025-02-22T15:16:09.734173Z",
     "shell.execute_reply": "2025-02-22T15:16:09.733460Z"
    },
    "papermill": {
     "duration": 0.076079,
     "end_time": "2025-02-22T15:16:09.735373",
     "exception": false,
     "start_time": "2025-02-22T15:16:09.659294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dtest = xgb.DMatrix(test_df[feature_cols])\n",
    "lgb_test_pred_log = lgb_model.predict(test_df[feature_cols], num_iteration=lgb_model.best_iteration)\n",
    "xgb_test_pred_log = xgb_model.predict(dtest, iteration_range=(0, xgb_model.best_iteration))\n",
    "cat_test_pred_log = cat_model.predict(test_df[feature_cols])\n",
    "ensemble_test_pred_log = (lgb_test_pred_log + xgb_test_pred_log + cat_test_pred_log) / 3.0\n",
    "test_df['total_fire_size'] = np.expm1(ensemble_test_pred_log)\n",
    "test_df.loc[test_df['total_fire_size'] < 0, 'total_fire_size'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5270193",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-22T15:16:09.761803Z",
     "iopub.status.busy": "2025-02-22T15:16:09.761574Z",
     "iopub.status.idle": "2025-02-22T15:16:09.792989Z",
     "shell.execute_reply": "2025-02-22T15:16:09.792092Z"
    },
    "papermill": {
     "duration": 0.045914,
     "end_time": "2025-02-22T15:16:09.794423",
     "exception": false,
     "start_time": "2025-02-22T15:16:09.748509",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df = test_df.sort_values(['STATE', 'month']).reset_index(drop=True)\n",
    "test_df['ID'] = test_df.index\n",
    "test_df['month'] = test_df['month'].dt.strftime('%Y-%m')\n",
    "submission = test_df[['ID', 'STATE', 'month', 'total_fire_size']].copy()\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"Final submission file saved as 'submission.csv'!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11174958,
     "sourceId": 93872,
     "sourceType": "competition"
    },
    {
     "datasetId": 6720524,
     "sourceId": 10823539,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6720710,
     "sourceId": 10823784,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 151.777085,
   "end_time": "2025-02-22T15:16:10.826377",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-22T15:13:39.049292",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
